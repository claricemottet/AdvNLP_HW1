{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdvNLP - HW1\n",
    "\n",
    "-Clarice Mottet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "Part 1: Rule-based Analysis using spaCy Matcher (2 points)\n",
    "- Objective: Utilize spaCy's Matcher to classify movie reviews as positive or negative based on predefined linguistic rules.\n",
    "- Tasks:\n",
    "  1. Positive Reviews Rule Creation (0.5 point): Develop a rule using spaCy's Matcher to identify phrases commonly found in positive reviews. Justify your choice of patterns.\n",
    "  2. Negative Reviews Rule Creation (0.5 point): Create a similar rule for detecting negative reviews. Explain the rationale behind the patterns selected.\n",
    "  3. Reducing False Positives (1 point): Propose and implement a rule to minimize false positives in your classifications. Discuss the improvements observed.\n",
    "\n",
    "Part 2: Machine Learning with TF-IDF and Logistic Regression (3 points)\n",
    "- Objective: Build and evaluate a sentiment analysis model using TF-IDF vectorization and logistic regression.\n",
    "- Tasks:\n",
    "  1. Model Fitting (0.5 points): Train a logistic regression model on TF-IDF vectors of the movie reviews.\n",
    "  2. Feature Importance Analysis (0.5 points): Identify and interpret the most influential features in your model.\n",
    "  3. Preprocessing Improvements (1 point): Experiment with different preprocessing techniques of your training set to enhance model performance. Summarize the impact of these modifications.\n",
    "  4. Word2Vec Embeddings (0.5 points each for a. and b.):\n",
    "     - a. Implement sentence embedding using the mean of word vectors and retrain your logistic regression model.\n",
    "     - b. Create sentence embeddings using TF-IDF weighted averages of word vectors and retrain the model. Compare this approach with the mean embedding technique. Comment\n",
    "\n",
    "Part 3: Recurrent Neural Networks (RNN) with Word2Vec (4 points)\n",
    "- Objective: Explore the application of RNNs for sentiment analysis, utilizing pre-trained Word2Vec embeddings.\n",
    "- Tasks:\n",
    "  1. RNN Implementation (2 point): Fit an RNN model with LSTM units using Word2Vec embeddings. Analyze and compare its performance with the TF-IDF based logistic regression model. Discuss any notable differences in results.\n",
    "  2. Word2Vec Vectors Analysis:\n",
    "     - Before and After Fine-Tuning (1 point): Examine the evolution of word vectors by comparing them before and after fine-tuning on the movie review dataset. Provide insights into the changes observed.\n",
    "     - Visualization and Commentary (1 point): Visualize the embeddings of select words before and after fine-tuning using a tool like t-SNE or PCA. Comment on any patterns or shifts in word associations.\n",
    "\n",
    "Submission Guidelines:\n",
    "- Document your code, analysis, and findings in a Jupyter notebook. 1 point on code quality\n",
    "- Include comments and markdown cells to explain your logic and interpretations at each step.\n",
    "\n",
    "- Submit the notebook file via colab.\n",
    "- Dataset: https://huggingface.co/datasets/rotten_tomatoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Rule-based Analysis using spaCy Matcher (2 points)\n",
    "- Objective: Utilize spaCy's Matcher to classify movie reviews as positive or negative based on predefined linguistic rules.\n",
    "- Tasks:\n",
    "  1. Positive Reviews Rule Creation (0.5 point): Develop a rule using spaCy's Matcher to identify phrases commonly found in positive reviews. Justify your choice of patterns.\n",
    "  2. Negative Reviews Rule Creation (0.5 point): Create a similar rule for detecting negative reviews. Explain the rationale behind the patterns selected.\n",
    "  3. Reducing False Positives (1 point): Propose and implement a rule to minimize false positives in your classifications. Discuss the improvements observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Machine Learning with TF-IDF and Logistic Regression (3 points)\n",
    "- Objective: Build and evaluate a sentiment analysis model using TF-IDF vectorization and logistic regression.\n",
    "- Tasks:\n",
    "  1. Model Fitting (0.5 points): Train a logistic regression model on TF-IDF vectors of the movie reviews.\n",
    "  2. Feature Importance Analysis (0.5 points): Identify and interpret the most influential features in your model.\n",
    "  3. Preprocessing Improvements (1 point): Experiment with different preprocessing techniques of your training set to enhance model performance. Summarize the impact of these modifications.\n",
    "  4. Word2Vec Embeddings (0.5 points each for a. and b.):\n",
    "     - a. Implement sentence embedding using the mean of word vectors and retrain your logistic regression model.\n",
    "     - b. Create sentence embeddings using TF-IDF weighted averages of word vectors and retrain the model. Compare this approach with the mean embedding technique. Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Recurrent Neural Networks (RNN) with Word2Vec (4 points)\n",
    "- Objective: Explore the application of RNNs for sentiment analysis, utilizing pre-trained Word2Vec embeddings.\n",
    "- Tasks:\n",
    "  1. RNN Implementation (2 point): Fit an RNN model with LSTM units using Word2Vec embeddings. Analyze and compare its performance with the TF-IDF based logistic regression model. Discuss any notable differences in results.\n",
    "  2. Word2Vec Vectors Analysis:\n",
    "     - Before and After Fine-Tuning (1 point): Examine the evolution of word vectors by comparing them before and after fine-tuning on the movie review dataset. Provide insights into the changes observed.\n",
    "     - Visualization and Commentary (1 point): Visualize the embeddings of select words before and after fine-tuning using a tool like t-SNE or PCA. Comment on any patterns or shifts in word associations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
